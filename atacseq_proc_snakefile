import glob

# Config file
configfile: "config.yml"

#working directory
#workdir: config['workdir']

# Paths
datadir = config["datadir"]

resdir= config["resdir"]

filtbamdir = resdir + "bam_filtered/"
filtbamdir_dup = resdir + "bam_filtered_noDupRm/"


logdir = config["logdir"]
rawbamdirstats= logdir + "bam_raw_stats/"
filtbamdirstats= logdir + "bam_filt_stats/"

qcdir= resdir + "qc/"
xcordir= qcdir + "xcor/"
fingerprintdir = qcdir + "deepTools_fingerprint/"
corrdir = qcdir + "deepTools_correlationHM/"


deeptoolsdir = resdir + "deepTools/"
covdir1x = deeptoolsdir + "coverage1x/"
covdirCPM = deeptoolsdir + "coverageCPM/"
hmdir = deeptoolsdir + "heatmaps_clust/"
deeptoolsdir_plots= deeptoolsdir + "plots/"

multiBamSummarydir= deeptoolsdir + "multiBamSummary/"

matrixDir= deeptoolsdir + "profiles/computeMatrix_cov1x/"
hmDir=deeptoolsdir + "profiles/heatmaps/"
matrixDirInd= deeptoolsdir + "profiles/computeMatrix_cov1x_samples/"
hmDirInd=deeptoolsdir + "profiles/heatmaps_samples/"

tmpdir= os.getenv('TMPDIR', default='/tmp')

tempdir= resdir + "temporary/"

# Get samples & file bases in the fastq data directory
bam_base = glob.glob(datadir + "*.bam")                  
bam_base = [s.replace('.bam', '') for s in bam_base]
bam_base = [s.replace(datadir, '') for s in bam_base]


#print(bam_base)


#####################
## TMPDIR

# in this version $TMPDIR is used in the shell code chunks
#####################


rule all:
    input:
        resdir + "rulegraph.png",
        resdir + "dag.png",
        expand(filtbamdirstats + "{id}.filt.stats", id=bam_base),
        expand(xcordir + "{id}.xcor.metrics.txt", id=bam_base),
        deeptoolsdir_plots + "CorrSpearman_bin5k.pdf",
        deeptoolsdir_plots + "bamFingerprint.pdf",
        expand(covdir1x + "{id}.norm1x.bw", id=bam_base),
        hmDir + "ensGene.cov1x.k4.pdf",
        expand(hmDirInd + "{id}.ensGene.cov1x.k3.pdf", id=bam_base)



rule filter_bam:
    input:
        datadir + "{id}.bam"
    output:
        filt= filtbamdir + "{id}.filt.bam",
        log_st_flagstat= rawbamdirstats + "{id}.raw.flagstat",
        log_st_idxstats= rawbamdirstats + "{id}.raw.idxstats",
        log_st_stats= rawbamdirstats + "{id}.raw.stats",
        log_picard= logdir + "{id}.MarkDuplicates.metrics.txt",
        log_Mt= logdir + "{id}.filt.Mt.log",
        log_blcklst= logdir + "{id}.filt.blacklist.log",
        nonduprm= filtbamdir_dup +  "{id}.filt.NOduprm.bam",
        nonduprm_idx= filtbamdir_dup +  "{id}.filt.NOduprm.bam.bai"
    shell:
        """
        module load bioinfo-tools
        module load samtools/1.9
        module load picard/2.20.4
        
        TMPDIR="${{TMPDIR:-/tmp}}"
        PICARD_HOME="${{PICARD_HOME}}"
    
        echo "sort, index and compute stats for bam file"

        samtools sort -T $TMPDIR/{wildcards.id}.tmp -o $TMPDIR/{wildcards.id}.sorted.bam {input}
        samtools index $TMPDIR/{wildcards.id}.sorted.bam
        
        samtools flagstat $TMPDIR/{wildcards.id}.sorted.bam > {output.log_st_flagstat}
        samtools idxstats $TMPDIR/{wildcards.id}.sorted.bam > {output.log_st_idxstats}
        samtools stats $TMPDIR/{wildcards.id}.sorted.bam > {output.log_st_stats}
    
        
        echo "aln quality filter"

        samtools view -q 1 -hbo $TMPDIR/{wildcards.id}.sorted.q.bam $TMPDIR/{wildcards.id}.sorted.bam

        echo "mark duplicates"

        java -Xmx6G -jar $PICARD_HOME/picard.jar MarkDuplicates I=$TMPDIR/{wildcards.id}.sorted.q.bam \
            O=$TMPDIR/{wildcards.id}.dedup.bam \
            M={output.log_picard} VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=false \
            ASSUME_SORTED=true TMP_DIR=$TMPDIR

        echo "index and filter reads mapped to Mt; and compute stats for bam file"

        # rm mt and blacklist
        samtools index $TMPDIR/{wildcards.id}.dedup.bam
        samtools view -b -L {config[mt]} -U $TMPDIR/{wildcards.id}.filtMT.bam -o $TMPDIR/{wildcards.id}.filtMT.in.bam $TMPDIR/{wildcards.id}.dedup.bam
        samtools index $TMPDIR/{wildcards.id}.filtMT.bam
        samtools index $TMPDIR/{wildcards.id}.filtMT.in.bam
        samtools flagstat $TMPDIR/{wildcards.id}.filtMT.in.bam > {output.log_Mt}
        
        echo "index and filter reads mapped to blacklist"

        samtools view -hb -L {config[blacklist]} -U $TMPDIR/{wildcards.id}.filt_Mt_blcklist.bam -o $TMPDIR/{wildcards.id}.filt_Mt_blcklist.in.bam $TMPDIR/{wildcards.id}.filtMT.bam
        
        echo "compute stats for filtered bam file"

        samtools index $TMPDIR/{wildcards.id}.filt_Mt_blcklist.bam
        samtools index $TMPDIR/{wildcards.id}.filt_Mt_blcklist.in.bam
        samtools flagstat $TMPDIR/{wildcards.id}.filt_Mt_blcklist.in.bam > {output.log_blcklst}

    
        cp $TMPDIR/{wildcards.id}.filt_Mt_blcklist.bam {output.nonduprm}
        cp $TMPDIR/{wildcards.id}.filt_Mt_blcklist.bam.bai {output.nonduprm_idx}
        
        echo "filter duplicate reads and index final bam file"

        # rm dups
        samtools view -h -F 1024 $TMPDIR/{wildcards.id}.filt_Mt_blcklist.bam | samtools sort -T $TMPDIR/{wildcards.id}.sort.tmp -o {output.filt} -
    
        samtools index {output.filt}
        """

rule bam_stats:
    input:
        filtbamdir + "{id}.filt.bam"
    output:
        log_st_stats= filtbamdirstats + "{id}.filt.stats",
        log_st_flagstat= filtbamdirstats + "{id}.filt.flagstat",
        log_st_idxstats= filtbamdirstats + "{id}.filt.idxstats"
    shell:
        """
        module load bioinfo-tools
        module load samtools/1.9

        samtools flagstat {input} > {output.log_st_flagstat}
        samtools idxstats {input} > {output.log_st_idxstats}
        samtools stats {input} > {output.log_st_stats}
        """

rule xcor:
    input:
        filtbamdir_dup +  "{id}.filt.NOduprm.bam"
    output:
        plot= xcordir + "{id}.xcor.pdf",
        met= xcordir + "{id}.xcor.metrics.txt"
    shell:
        """
        module load bioinfo-tools
        module unload gcc
        module load phantompeakqualtools/1.1

        run_spp.R -c={input} -savp={output.plot} -out={output.met}
        """

rule multiBamSummary:
    input:
        expand(filtbamdir + "{id}.filt.bam", id=bam_base)
    output:
        multiBamSummarydir + "multiBamSum_bin_5k.npz"
    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0

        multiBamSummary bins --bamfiles {input} --outFileName {output} --binSize=5000 --numberOfProcessors=4 --extendReads={config[extSize]}
        """

rule plotCorrelation:
    input:
        multiBamSummarydir + "multiBamSum_bin_5k.npz"
    output:
        deeptoolsdir_plots + "CorrSpearman_bin5k.pdf"
    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0

        plotCorrelation --corData {input} --corMethod spearman --whatToPlot heatmap --plotFile {output} \
            --skipZeros --plotFileFormat pdf --plotNumbers
        """
rule plotFingerprint:
    input:
        expand(filtbamdir + "{id}.filt.bam", id=bam_base)
    output:
        deeptoolsdir_plots + "bamFingerprint.pdf"
    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0

        plotFingerprint --bamfiles {input} --extendReads {config[extSize]} --binSize=1000 --plotFile {output} --numberOfProcessors=1
        """

rule bamCoverage:
    input:
        filtbamdir + "{id}.filt.bam"
    output:
         bw1x= covdir1x + "{id}.norm1x.bw",
         bg1x= covdir1x + "{id}.norm1x.bg",
         bwCPM= covdirCPM + "{id}.normCPM.bw",
         bgCPM= covdirCPM + "{id}.normCPM.bg"
    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0

        bamCoverage --bam {input} --outFileName {output.bw1x} --normalizeUsing RPGC --effectiveGenomeSize {config[efGenomeSize]} --extendReads {config[extSize]} --binSize 50 --outFileFormat bigwig --ignoreForNormalization X Y -p 5

        bamCoverage --bam {input} --outFileName {output.bg1x} --normalizeUsing RPGC --effectiveGenomeSize {config[efGenomeSize]} --extendReads {config[extSize]} --binSize 50 --outFileFormat bedgraph --ignoreForNormalization X Y -p 5


        bamCoverage --bam {input} --outFileName {output.bwCPM} --normalizeUsing CPM --extendReads {config[extSize]} --binSize 50 --outFileFormat bigwig --ignoreForNormalization X Y -p 5

        bamCoverage --bam {input} --outFileName {output.bgCPM} --normalizeUsing CPM --extendReads {config[extSize]} --binSize 50 --outFileFormat bedgraph --ignoreForNormalization X Y -p 5

        """


rule computeMatrix_EnsGene:
    input:
        expand (covdir1x + "{id}.norm1x.bw", id=bam_base)
    output:
        ens_gene= matrixDir + "ensGene.cov1x.computeMatrix.gz"
    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0

        computeMatrix reference-point -b 1000 -a 1000 --binSize 10 -p max -S {input} -R {config[ens5gene]} -o {output.ens_gene}

        """


rule computeMatrix_refTSS:
    input:
        expand (covdir1x + "{id}.norm1x.bw", id=bam_base)
    output:
        all_TSS= matrixDir + "refTSS.cov1x.computeMatrix.gz"
    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0

        computeMatrix reference-point -b 1000 -a 1000 --binSize 10 -p max -S {input} -R {config[allTSS]} -o {output.all_TSS}
        """

rule computeMatrix_refTSStrx:
    input:
        expand (covdir1x + "{id}.norm1x.bw", id=bam_base)
    output:
        trx_TSS= matrixDir + "refTSStrx.cov1x.computeMatrix.gz"
    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0

        computeMatrix reference-point -b 1000 -a 1000 --binSize 10 -p max -S {input} -R {config[trxTSS]} -o {output.trx_TSS}

        """



rule computeMatrix_samples:
    input:
        covdir1x + "{id}.norm1x.bw"
    output:
        ens_gene= matrixDirInd + "{id}.ensGene.cov1x.computeMatrix.gz"

    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0

        computeMatrix reference-point -b 1000 -a 1000 --binSize 10 -p max -S {input} -R {config[ens5gene]} -o {output.ens_gene}

        """


rule plotHeatmap:
    input:
        ens_gene= matrixDir + "ensGene.cov1x.computeMatrix.gz",
        all_TSS= matrixDir + "refTSS.cov1x.computeMatrix.gz",
        trx_TSS= matrixDir + "refTSStrx.cov1x.computeMatrix.gz"
    output:
        ens_gene= hmDir + "ensGene.cov1x.k4.pdf",
        all_TSS= hmDir + "refTSS.cov1x.k4.pdf",
        trx_TSS= hmDir + "refTSStrx.cov1x.k4.pdf"
    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0
        
        plotHeatmap --matrixFile {input.ens_gene} --outFileName {output.ens_gene} --kmeans 4 --sortRegions descend --sortUsing median -p 5

        plotHeatmap --matrixFile {input.all_TSS} --outFileName {output.all_TSS} --kmeans 4 --sortRegions descend --sortUsing median -p 5

        plotHeatmap --matrixFile {input.trx_TSS} --outFileName {output.trx_TSS} --kmeans 4 --sortRegions descend --sortUsing median -p 5

        """


rule plotHeatmap_samples:
    input:
        matrixDirInd + "{id}.ensGene.cov1x.computeMatrix.gz"
    output:
        k3= hmDirInd + "{id}.ensGene.cov1x.k3.pdf",
        k4= hmDirInd + "{id}.ensGene.cov1x.k4.pdf"
    shell:
        """
        module load bioinfo-tools
        module load deepTools/3.1.0
        
        plotHeatmap --matrixFile {input} --outFileName {output.k3} --kmeans 3 --sortRegions descend --sortUsing median -p 5
        plotHeatmap --matrixFile {input} --outFileName {output.k4} --kmeans 4 --sortRegions descend --sortUsing median -p 5

        """


################################
## final rules
################################

rule generate_rulegraph:
    """
    Generate a rulegraph for the workflow.
    """
    output:
        resdir + "rulegraph.png",
        resdir + "dag.png"
    shell:
        """
        snakemake --snakefile {config[snkpth]} --config max_reads=0 --rulegraph | dot -Tpng >{output[0]}
        snakemake --snakefile {config[snkpth]} --config max_reads=0 --dag | dot -Tpng >{output[1]}
        """

